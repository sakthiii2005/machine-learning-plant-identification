{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython as Ip\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Dropout\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 111265 files belonging to 449 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(\"D:\", os.path.sep, \"Web Development\", \"Leaf\"),\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    image_size=(224,224),\n",
    ")\n",
    "labels = np.array(dataset.class_names).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 44 17\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(ds,train_size=0.8,test_size=0.2,shuffles=10000):\n",
    "    if shuffles:\n",
    "        ds.shuffle(shuffles,seed=42)\n",
    "    train_size = int(train_size*len(ds))\n",
    "    test_size = int(test_size * len(ds))\n",
    "    train_ds = ds.take(train_size)\n",
    "    test_ds = ds.skip(train_size)\n",
    "    val_ds = test_ds.take(int(test_size*0.4))\n",
    "    return train_ds,test_ds,val_ds\n",
    "\n",
    "train_dataset,test_dataset,val_dataset = get_dataset(dataset)\n",
    "print(len(train_dataset),len(test_dataset),len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNet_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='max')\n",
    "\n",
    "for layer in DenseNet_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(DenseNet_model.output)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "output = Dense(len(labels), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=DenseNet_model.input, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                validation_data=val_dataset,\n",
    "                #callbacks=[early_stop],\n",
    "                epochs=30,\n",
    "                batch_size=32            \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Cnn.pickle','wb') as saved_model:\n",
    "#    pickle.dump(model,saved_model)\n",
    "with open('Cnn.pickle','rb') as saved_model:\n",
    "    loaded_model = pickle.load(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m696/696\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1679s\u001b[0m 2s/step - accuracy: 0.6094 - loss: 1.5207\n"
     ]
    }
   ],
   "source": [
    "test = loaded_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5313717126846313, 0.6068522334098816]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_with_loaded_model(imgs):\n",
    "    imgs = tf.keras.preprocessing.image.load_img(imgs,target_size=(224,224))\n",
    "    imgs = tf.keras.preprocessing.image.img_to_array(imgs)\n",
    "    imgs = tf.expand_dims(imgs,0)\n",
    "    \n",
    "    predict = loaded_model.predict(imgs)\n",
    "    score = tf.nn.sigmoid(predict[0])\n",
    "    \n",
    "    print(f'This image likely belongs to {labels[np.argmax(score)]} with the accuracy of {100 * np.max(score)}% .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "This image likely belongs to ['CallaLily'] with the accuracy of 61.59018278121948% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r\"D:\\Images\\bamboo2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "This image likely belongs to ['Amruthaballi'] with the accuracy of 60.99408268928528% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r\"D:\\Images\\mango.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "This image likely belongs to ['Amruthaballi'] with the accuracy of 60.99408268928528% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r\"D:\\Images\\mango.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "This image likely belongs to ['Poinsettia'] with the accuracy of 54.446154832839966% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\Hibiscus_flower_TZ.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "This image likely belongs to ['Poinsettia'] with the accuracy of 73.07265400886536% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\poinsettia.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "This image likely belongs to ['Amaryllis'] with the accuracy of 70.87454199790955% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\images.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "This image likely belongs to ['Amaryllis'] with the accuracy of 72.77393937110901% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\Amarylis.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "This image likely belongs to ['Nithyapushpa'] with the accuracy of 62.69795894622803% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\Tulsi.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "This image likely belongs to ['MoonflowerVine'] with the accuracy of 61.12087368965149% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\Nithyapushpa.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "This image likely belongs to ['MoonflowerVine'] with the accuracy of 72.00932502746582% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\MoonflowerVine.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "This image likely belongs to ['Amaryllis'] with the accuracy of 68.5032844543457% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\Hybiscus2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "This image likely belongs to ['Poinsettia'] with the accuracy of 67.9844856262207% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\Hyb.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "This image likely belongs to ['Roses'] with the accuracy of 60.69513559341431% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\rose.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "This image likely belongs to ['OrientalLily'] with the accuracy of 61.335289478302% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\lotus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "This image likely belongs to ['OrientalLily'] with the accuracy of 57.92946815490723% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\orientallily.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "This image likely belongs to ['Calendula'] with the accuracy of 59.0083122253418% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\sunflower.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "This image likely belongs to ['Calendula'] with the accuracy of 72.69576787948608% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r'D:\\Web Development\\Css-html\\calendula.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "This image likely belongs to ['Ganike'] with the accuracy of 57.66265392303467% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r\"D:\\Web Development\\Leaf\\Ganike\\20200402_085547_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "This image likely belongs to ['BabysBreath'] with the accuracy of 71.83054685592651% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r\"D:\\Web Development\\Leaf\\BabysBreath\\21dd358f72.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "This image likely belongs to ['Jasmine'] with the accuracy of 61.50609254837036% .\n"
     ]
    }
   ],
   "source": [
    "prediction_with_loaded_model(r\"D:\\Web Development\\Leaf\\Jasmine\\1b55e441fe.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
